{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style=\"color: Cyan;\"> Objective 1: Image Classifier using CNN</span></h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "|Name|Class|Admin Number|\n",
    "|:----:|:----:|:----:|\n",
    "|Muhammad Fitri Amir bin Abdullah|DAAA/FT/2B/06|2222811|\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "In this task, I aim to implement an image classifier using a Convolutional Neural Network in order to classify a dataset that contains 15 different types of vegetables. There are some steps given that I will need to adhere to such as: \n",
    "- converting the image into grayscale (1 channel instead of 3)\n",
    "- making 1 model for 2 inputs, 31x31 pixels and 128x128 pixels, NOT 224.\n",
    "\n",
    "Looking at the metadata of the dataset given, here's some useful information:\n",
    "- Total 15 Classes of 3000 images; means that this is a multi-class classification task.\n",
    "- Each class contain 200 images\n",
    "- Size of each image is 224*224 and images are in *.jpg format.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os, time, math, datetime, warnings, pytz, glob, PIL\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from functools import reduce, wraps\n",
    "from sklearn.metrics import classification_report,accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "custom  = {\"axes.edgecolor\" : \"white\", \n",
    "            \"grid.linestyle\": \"dashed\",\n",
    "            \"grid.color\": \"gray\"\n",
    "            }\n",
    "sns.set_style(\"whitegrid\", rc = custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Checking that GPU is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17976915722486779140\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2254123828\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10687980857566736494\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  2 14:31:11 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 496.49       Driver Version: 496.49       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   58C    P8     4W /  N/A |    302MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      6256      C   ...3\\envs\\gpu_env\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     15780    C+G   ...-3.748.0\\MedalEncoder.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Importing dataset and preparing test/train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (15028,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Fitri\\OneDrive\\Documents\\GitHub\\poly\\Deep Learning\\CA1\\CNN\\BaseImplementation.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Fitri/OneDrive/Documents/GitHub/poly/Deep%20Learning/CA1/CNN/BaseImplementation.ipynb#X25sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m             labels\u001b[39m.\u001b[39mappend(label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Fitri/OneDrive/Documents/GitHub/poly/Deep%20Learning/CA1/CNN/BaseImplementation.ipynb#X25sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Convert lists to numpy arrays\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Fitri/OneDrive/Documents/GitHub/poly/Deep%20Learning/CA1/CNN/BaseImplementation.ipynb#X25sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Fitri/OneDrive/Documents/GitHub/poly/Deep%20Learning/CA1/CNN/BaseImplementation.ipynb#X25sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Fitri/OneDrive/Documents/GitHub/poly/Deep%20Learning/CA1/CNN/BaseImplementation.ipynb#X25sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Print the shapes of X and y to verify\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (15028,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "dataset_path = \"Datasets/Dataset for CA1 part A/\"\n",
    "\n",
    "# Initialize empty lists to store images and corresponding labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop through train, test, and validation folders\n",
    "for folder in [\"train\", \"test\", \"validation\"]:\n",
    "    folder_path = os.path.join(dataset_path, folder)\n",
    "    for label in os.listdir(folder_path):\n",
    "        label_path = os.path.join(folder_path, label)\n",
    "        for image_file in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_file)\n",
    "            # Read the image using OpenCV\n",
    "            image = cv2.imread(image_path)\n",
    "            # Resize the image to desired dimensions\n",
    "            # image = cv2.resize(image, (desired_width, desired_height))\n",
    "            # Normalize the pixel values\n",
    "            image = image.astype('float32') / 255\n",
    "            # Add the preprocessed image and label to the lists\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Print the shapes of X and y to verify\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Fitri\\OneDrive\\Documents\\GitHub\\poly\\Deep Learning\\CA1\\CNN\\BaseImplementation.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Fitri/OneDrive/Documents/GitHub/poly/Deep%20Learning/CA1/CNN/BaseImplementation.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Fitri/OneDrive/Documents/GitHub/poly/Deep%20Learning/CA1/CNN/BaseImplementation.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m22\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Fitri/OneDrive/Documents/GitHub/poly/Deep%20Learning/CA1/CNN/BaseImplementation.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     randn \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandom() \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(X_train))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Fitri/OneDrive/Documents/GitHub/poly/Deep%20Learning/CA1/CNN/BaseImplementation.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     ax \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39madd_subplot(\u001b[39m3\u001b[39m, \u001b[39m7\u001b[39m, i)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Fitri/OneDrive/Documents/GitHub/poly/Deep%20Learning/CA1/CNN/BaseImplementation.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     ax\u001b[39m.\u001b[39mimshow(X_train[randn])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20, 6))\n",
    "for i in range(1,22):\n",
    "    randn = int(np.random.random() * len(X_train))\n",
    "    ax = fig.add_subplot(3, 7, i)\n",
    "    ax.imshow(X_train[randn])\n",
    "    ax.set_title(labels[y_train.flatten()[randn]])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Dataset: <br>\n",
    "https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset <br>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
