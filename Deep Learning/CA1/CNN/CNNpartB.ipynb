{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style=\"color: #5D3FD3;\"> Objective 1: Image Classifier using CNN</span></h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "|Name|Class|Admin Number|\n",
    "|:----:|:----:|:----:|\n",
    "|Muhammad Fitri Amir bin Abdullah|DAAA/FT/2B/06|2222811|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os, time, math, datetime, warnings, pytz, glob, PIL\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from functools import reduce, wraps\n",
    "from sklearn.metrics import classification_report,accuracy_score, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input, concatenate, Activation, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "from tensorflow.keras.regularizers import L1, L2\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "custom  = {\"axes.edgecolor\" : \"white\", \n",
    "            \"grid.linestyle\": \"dashed\",\n",
    "            \"grid.color\": \"gray\"\n",
    "            }\n",
    "sns.set_style(\"whitegrid\", rc = custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pic(dataset_path, filename):\n",
    "    images = []\n",
    "    labels = []\n",
    "    folder_path = os.path.join(dataset_path, filename)\n",
    "    for label in os.listdir(folder_path):\n",
    "        label_path = os.path.join(folder_path, label)\n",
    "        for image_file in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_file)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (31, 31))\n",
    "            image = image.astype('float32')\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    #         images = np.array(images)\n",
    "    #         labels = np.array(labels)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def preprocess(train, test, val):\n",
    "\n",
    "    # unpack data\n",
    "    X_train, y_train = train\n",
    "    X_test, y_test = test\n",
    "    X_val, y_val = val\n",
    "\n",
    "    # normalize pixel values\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    X_val = X_val / 255.0\n",
    "\n",
    "    # Reshape the data (assuming 128x128 images)\n",
    "    input_shape = (31, 31, 1)  # Adjust based on your image size and channels\n",
    "    X_train = X_train.reshape(X_train.shape[0], *input_shape)\n",
    "    X_test = X_test.reshape(X_test.shape[0], *input_shape)\n",
    "    X_val = X_val.reshape(X_val.shape[0], *input_shape)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "    y_val = label_encoder.transform(y_val)\n",
    "\n",
    "    # one hot encode labels\n",
    "    y_train = to_categorical(y_train, num_classes = len(np.unique(y_train)))\n",
    "    y_test = to_categorical(y_test, num_classes= len(np.unique(y_test)))\n",
    "    y_val = to_categorical(y_val, num_classes= len(np.unique(y_val)))\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test), (X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Datasets/Dataset for CA1 part A/\"\n",
    "\n",
    "# Load training images and labels\n",
    "train_images, train_labels = read_pic(dataset_path, \"train\")\n",
    "X_train = np.array(train_images)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "# Load test images and labels\n",
    "test_images, test_labels = read_pic(dataset_path, \"test\")\n",
    "X_test = np.array(test_images)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "val_images, val_labels = read_pic(dataset_path, \"validation\")\n",
    "X_val = np.array(val_images)\n",
    "y_val = np.array(val_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
